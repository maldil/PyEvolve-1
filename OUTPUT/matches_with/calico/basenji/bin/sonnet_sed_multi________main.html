<link rel="stylesheet" href="../../..//default.css">
<script src="../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/calico/basenji/blob/master/bin/sonnet_sed_multi.py#L41">GitHubLink</a>


<a href="https://github.com/maldil/basenji/blob/master/bin/sonnet_sed_multi.py#L41">GitMyHubLink</a>

&#47&#47!/usr/bin/env python
&#47&#47 Copyright 2017 Calico LLC

&#47&#47 Licensed under the Apache License, Version 2.0 (the "License");
&#47&#47 you may not use this file except in compliance with the License.
&#47&#47 You may obtain a copy of the License at

&#47&#47     https://www.apache.org/licenses/LICENSE-2.0

&#47&#47 Unless required by applicable law or agreed to in writing, software
&#47&#47 distributed under the License is distributed on an "AS IS" BASIS,
&#47&#47 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
&#47&#47 See the License for the specific language governing permissions and
&#47&#47 limitations under the License.
&#47&#47 =========================================================================

from optparse import OptionParser
import glob
import os
import pdb
import pickle
import shutil
import subprocess
import sys

import h5py
import numpy as np

import slurm


sonnet_sed_multi.py

Compute SNP expression difference scores for variants in a VCF file,
using multiple processes.


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 main
&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
def main():
  <a id="change">usage = &quotusage: %prog [options] &lt;model_file&gt; &lt;vcf_file&gt;&quot</a>
  <a id="change">parser = OptionParser(usage)</a>

  &#47&#47 sed
  parser.add_option(&quot-b&quot, dest=&quotbatch_size&quot,
      default=4, type=&quotint&quot,
      help=&quotBatch size [Default: %default]&quot)
  parser.add_option(&quot-c&quot, dest=&quotslice_center&quot,
      default=None, type=&quotint&quot,
      help=&quotSlice center positions [Default: %default]&quot)
  parser.add_option(&quot-f&quot, dest=&quotgenome_fasta&quot,
      default=&quot%s/data/hg38.fa&quot % os.environ[&quotBASENJIDIR&quot],
      help=&quotGenome FASTA for sequences [Default: %default]&quot)
  parser.add_option(&quot-n&quot, dest=&quotnorm_file&quot,
      default=None,
      help=&quotNormalize SAD scores&quot)
  parser.add_option(&quot-o&quot,dest=&quotout_dir&quot,
      default=&quotsed&quot,
      help=&quotOutput directory for tables and plots [Default: %default]&quot)
  parser.add_option(&quot--pseudo&quot, dest=&quotlog_pseudo&quot,
      default=1, type=&quotfloat&quot,
      help=&quotLog2 pseudocount [Default: %default]&quot)
  parser.add_option(&quot--rc&quot, dest=&quotrc&quot,
      default=False, action=&quotstore_true&quot,
      help=&quotAverage forward and reverse complement predictions [Default: %default]&quot)
  parser.add_option(&quot--shifts&quot, dest=&quotshifts&quot,
      default=&quot0&quot, type=&quotstr&quot,
      help=&quotEnsemble prediction shifts [Default: %default]&quot)
  parser.add_option(&quot--species&quot, dest=&quotspecies&quot,
      default=&quothuman&quot)
  parser.add_option(&quot--stats&quot, dest=&quotsed_stats&quot,
      default=&quotSED&quot,
      help=&quotComma-separated list of stats to save. [Default: %default]&quot)
  parser.add_option(&quot-t&quot, dest=&quottargets_file&quot,
      default=None, type=&quotstr&quot,
      help=&quotFile specifying target indexes and labels in table format&quot)

  &#47&#47 multi
  parser.add_option(&quot--cpu&quot, dest=&quotcpu&quot,
      default=False, action=&quotstore_true&quot,
      help=&quotRun without a GPU [Default: %default]&quot)
  parser.add_option(&quot-e&quot, dest=&quotconda_env&quot,
      default=&quottf2.6&quot,
      help=&quotAnaconda environment [Default: %default]&quot)
  parser.add_option(&quot--name&quot, dest=&quotname&quot,
      default=&quotsed&quot, help=&quotSLURM name prefix [Default: %default]&quot)
  parser.add_option(&quot--max_proc&quot, dest=&quotmax_proc&quot,
      default=None, type=&quotint&quot,
      help=&quotMaximum concurrent processes [Default: %default]&quot)
  parser.add_option(&quot-p&quot, dest=&quotprocesses&quot,
      default=None, type=&quotint&quot,
      help=&quotNumber of processes, passed by multi script&quot)
  parser.add_option(&quot-q&quot, dest=&quotqueue&quot,
      default=&quotgeforce&quot,
      help=&quotSLURM queue on which to run the jobs [Default: %default]&quot)
  parser.add_option(&quot-r&quot, dest=&quotrestart&quot,
      default=False, action=&quotstore_true&quot,
      help=&quotRestart a partially completed job [Default: %default]&quot)
  <a id="change">(options, args) = parser.parse_args()</a>

  if len(args) != 3:
    parser.error(&quotMust provide model, variant VCF, and TSS BED.&quot)
  else:
    <a id="change">model_file = args[0]</a>
    <a id="change">vcf_file = args[1]</a>
    <a id="change">tss_bed_file = args[2]</a>

  &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
  &#47&#47 prep work

  &#47&#47 output directory
  if not options.restart:
    if os.path.isdir(options.out_dir):
      print(&quotPlease remove %s&quot % options.out_dir, file=sys.stderr)
      exit(1)
    os.mkdir(options.out_dir)

  &#47&#47 pickle options
  <a id="change">options_pkl_file = &quot%s/options.pkl&quot % options.out_dir</a>
  <a id="change">options_pkl = open(options_pkl_file, &quotwb&quot)</a>
  pickle.dump(options, options_pkl)
  <a id="change">options_pkl</a><a id="change">.close()</a>

  &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
  &#47&#47 launch worker threads
  <a id="change">jobs = []</a>
  for pi in range(options.processes):
    if not options.restart or not job_completed(options, pi):
      if options.cpu:
        <a id="change">cmd = &quot&quot</a>
      else:
        <a id="change">cmd = &quot. /home/drk/anaconda3/etc/profile.d/conda.sh;&quot</a>
        cmd += &quot conda activate %s;&quot % options.conda_env

      cmd += &quot time sonnet_sed.py %s %s %d&quot % (
          options_pkl_file, &quot &quot.join(args), pi)

      <a id="change">name = &quot%s_p%d&quot % (options.name, pi)</a>
      <a id="change">outf = &quot%s/job%d.out&quot % (options.out_dir, pi)</a>
      <a id="change">errf = &quot%s/job%d.err&quot % (options.out_dir, pi)</a>

      <a id="change">num_gpu = 1*(not options.cpu)</a>

      <a id="change">j = slurm.Job(cmd, name,
          outf, errf,
          queue=options.queue, gpu=num_gpu,
          mem=45000, time=&quot7-0:0:0&quot)</a>
      jobs.append(j)

  slurm.multi_run(jobs, max_proc=options.max_proc, verbose=True,
                  launch_sleep=10, update_sleep=60)

  &#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
  &#47&#47 collect output

  collect_h5(&quotsed.h5&quot, options.out_dir, options.processes)

  &#47&#47 for pi in range(options.processes):
  &#47&#47     shutil.rmtree(&quot%s/job%d&quot % (options.out_dir,pi))


def collect_h5(file_name, out_dir, num_procs):
  &#47&#47 count variants
  num_scores = 0
  for pi in range(num_procs):
    &#47&#47 open job
    job_h5_file = &quot%s/job%d/%s&quot % (out_dir, pi, file_name)
    job_h5_open = h5py.File(job_h5_file, &quotr&quot)
    num_scores += len(job_h5_open[&quotsnp&quot])
    job_h5_open.close()

  &#47&#47 initialize final h5
  final_h5_file = &quot%s/%s&quot % (out_dir, file_name)
  final_h5_open = h5py.File(final_h5_file, &quotw&quot)

  &#47&#47 keep dict for string values
  final_strings = {}

  job0_h5_file = &quot%s/job0/%s&quot % (out_dir, file_name)
  job0_h5_open = h5py.File(job0_h5_file, &quotr&quot)
  for key in job0_h5_open.keys():
    if key in [&quotpercentiles&quot, &quottarget_ids&quot, &quottarget_labels&quot]:
      &#47&#47 copy
      final_h5_open.create_dataset(key, data=job0_h5_open[key])

    elif key[-4:] == &quot_pct&quot:
      values = np.zeros(job0_h5_open[key].shape)
      final_h5_open.create_dataset(key, data=values)

    elif job0_h5_open[key].dtype.char == &quotS&quot:
        final_strings[key] = []

    elif job0_h5_open[key].ndim == 1:
      final_h5_open.create_dataset(key, shape=(num_scores,), dtype=job0_h5_open[key].dtype)

    else:
      num_targets = job0_h5_open[key].shape[1]
      final_h5_open.create_dataset(key, shape=(num_scores, num_targets), dtype=job0_h5_open[key].dtype)

  job0_h5_open.close()

  &#47&#47 set values
  vi = 0
  for pi in range(num_procs):
    &#47&#47 open job
    job_h5_file = &quot%s/job%d/%s&quot % (out_dir, pi, file_name)
    job_h5_open = h5py.File(job_h5_file, &quotr&quot)

    &#47&#47 append to final
    for key in job_h5_open.keys():
      if key in [&quotpercentiles&quot, &quottarget_ids&quot, &quottarget_labels&quot]:
        &#47&#47 once is enough
        pass

      elif key[-4:] == &quot_pct&quot:
        &#47&#47 average
        u_k1 = np.array(final_h5_open[key])
        x_k = np.array(job_h5_open[key])
        final_h5_open[key][:] = u_k1 + (x_k - u_k1) / (pi+1)

      else:
        if job_h5_open[key].dtype.char == &quotS&quot:
          final_strings[key] += list(job_h5_open[key])
        else:
          job_variants = job_h5_open[key].shape[0]
          final_h5_open[key][vi:vi+job_variants] = job_h5_open[key]

    vi += job_variants
    job_h5_open.close()

  &#47&#47 create final string datasets
  for key in final_strings:
    final_h5_open.create_dataset(key,
      data=np.array(final_strings[key], dtype=&quotS&quot))

  final_h5_open.close()


def job_completed(options, pi):
  Check whether a specific job has generated its
     output file.
  out_file = &quot%s/job%d/sed.h5&quot % (options.out_dir, pi)
  return os.path.isfile(out_file) or os.path.isdir(out_file)


&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
&#47&#47 __main__
&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47&#47
if __name__ == &quot__main__&quot:
  main()
</code></pre>