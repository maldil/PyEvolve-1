<link rel="stylesheet" href="../../../../..//default.css">
<script src="../../../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/stanfordnlp/stanza/blob/main/stanza/tests/common/test_utils.py#L20">GitHubLink</a>


<a href="https://github.com/maldil/stanza/blob/main/stanza/tests/common/test_utils.py#L20">GitMyHubLink</a>

import tempfile

import pytest

import stanza
import stanza.models.common.utils as utils
from stanza.tests import *

pytestmark = [pytest.mark.travis, pytest.mark.pipeline]

def test_wordvec_not_found():
    
    get_wordvec_file should fail if neither word2vec nor fasttext exists
    
    with tempfile.TemporaryDirectory(dir=f&quot{TEST_WORKING_DIR}/out&quot) as temp_dir:
        with pytest.raises(FileNotFoundError):
            utils.get_wordvec_file(wordvec_dir=temp_dir, shorthand=&quoten_foo&quot)


def test_word2vec_xz():
    
    Test searching for word2vec and xz files
    
    with tempfile.TemporaryDirectory(dir=f&quot{TEST_WORKING_DIR}/out&quot) as <a id="change">temp_dir</a>:
        &#47&#47 make a fake directory for English word vectors
        <a id="change">word2vec_dir</a> = os.path.join(temp_dir, &quotword2vec&quot, &quotEnglish&quot)
        os.makedirs(word2vec_dir)

        &#47&#47 make a fake English word vector file
        <a id="change">fake_file</a> = os.path.join(word2vec_dir, &quoten.vectors.xz&quot)
        <a id="change">fout</a><a id="change"> = open(fake_file, &quotw&quot)</a>
        <a id="change">fout</a><a id="change">.close()</a>

        &#47&#47 get_wordvec_file should now find this fake file
        filename = utils.get_wordvec_file(wordvec_dir=temp_dir, shorthand=&quoten_foo&quot)
        assert filename == fake_file

def test_fasttext_txt():
    
    Test searching for fasttext and txt files
    
    with tempfile.TemporaryDirectory(dir=f&quot{TEST_WORKING_DIR}/out&quot) as temp_dir:
        &#47&#47 make a fake directory for English word vectors
        fasttext_dir = os.path.join(temp_dir, &quotfasttext&quot, &quotEnglish&quot)
        os.makedirs(fasttext_dir)

        &#47&#47 make a fake English word vector file
        fake_file = os.path.join(fasttext_dir, &quoten.vectors.txt&quot)
        fout = open(fake_file, &quotw&quot)
        fout.close()

        &#47&#47 get_wordvec_file should now find this fake file
        filename = utils.get_wordvec_file(wordvec_dir=temp_dir, shorthand=&quoten_foo&quot)
        assert filename == fake_file

def test_wordvec_type():
    
    If we supply our own wordvec type, get_wordvec_file should find that
    
    with tempfile.TemporaryDirectory(dir=f&quot{TEST_WORKING_DIR}/out&quot) as temp_dir:
        &#47&#47 make a fake directory for English word vectors
        google_dir = os.path.join(temp_dir, &quotgoogle&quot, &quotEnglish&quot)
        os.makedirs(google_dir)

        &#47&#47 make a fake English word vector file
        fake_file = os.path.join(google_dir, &quoten.vectors.txt&quot)
        fout = open(fake_file, &quotw&quot)
        fout.close()

        &#47&#47 get_wordvec_file should now find this fake file
        filename = utils.get_wordvec_file(wordvec_dir=temp_dir, shorthand=&quoten_foo&quot, wordvec_type=&quotgoogle&quot)
        assert filename == fake_file

        &#47&#47 this file won&quott be found using the normal defaults
        with pytest.raises(FileNotFoundError):
            utils.get_wordvec_file(wordvec_dir=temp_dir, shorthand=&quoten_foo&quot)

def test_sort_with_indices():
    data = [[1, 2, 3], [4, 5], [6]]
    ordered, orig_idx = utils.sort_with_indices(data, key=len)
    assert ordered == ([6], [4, 5], [1, 2, 3])
    assert orig_idx == (2, 1, 0)

    unsorted = utils.unsort(ordered, orig_idx)
    assert data == unsorted

def test_empty_sort_with_indices():
    ordered, orig_idx = utils.sort_with_indices([])
    assert len(ordered) == 0
    assert len(orig_idx) == 0

    unsorted = utils.unsort(ordered, orig_idx)
    assert [] == unsorted


def test_split_into_batches():
    data = []
    for i in range(5):
        data.append(["Unban", "mox", "opal", str(i)])

    data.append(["Do", "n&quott", "ban", "Urza", "&quots", "Saga", "that", "card", "is", "great"])
    data.append(["Ban", "Ragavan"])

    &#47&#47 small batches will put one element in each interval
    batches = utils.split_into_batches(data, 5)
    assert batches == [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7)]

    &#47&#47 this one has a batch interrupted in the middle by a large element
    batches = utils.split_into_batches(data, 8)
    assert batches == [(0, 2), (2, 4), (4, 5), (5, 6), (6, 7)]

    &#47&#47 this one has the large element at the start of its own batch
    batches = utils.split_into_batches(data[1:], 8)
    assert batches == [(0, 2), (2, 4), (4, 5), (5, 6)]

    &#47&#47 overloading the test!  assert that the key & reverse is working
    ordered, orig_idx = utils.sort_with_indices(data, key=len, reverse=True)
    assert [len(x) for x in ordered] == [10, 4, 4, 4, 4, 4, 2]

    &#47&#47 this has the large element at the start
    batches = utils.split_into_batches(ordered, 8)
    assert batches == [(0, 1), (1, 3), (3, 5), (5, 7)]

    &#47&#47 double check that unsort is working as expected
    assert data == utils.unsort(ordered, orig_idx)


def test_find_missing_tags():
    assert utils.find_missing_tags(["O", "PER", "LOC"], ["O", "PER", "LOC"]) == []
    assert utils.find_missing_tags(["O", "PER", "LOC"], ["O", "PER", "LOC", "ORG"]) == [&quotORG&quot]
    assert utils.find_missing_tags([["O", "PER"], ["O", "LOC"]], [["O", "PER"], ["LOC", "ORG"]]) == [&quotORG&quot]
</code></pre>