<link rel="stylesheet" href="../..//default.css">
<script src="../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/huazhengwang/BanditLib/blob/master/YahooExp_util_functions.py#L196">GitHubLink</a>


<a href="https://github.com/maldil/BanditLib/blob/master/YahooExp_util_functions.py#L196">GitMyHubLink</a>

import re  &#47&#47 regular expression library
from random import random, choice  &#47&#47 for random strategy
from operator import itemgetter
import numpy as np
from scipy.sparse import csgraph
from scipy.spatial import distance
import pickle

&#47&#47 import matplotlib.pyplot as plt


def vectorize(M):
    temp = []
    for i in range(M.shape[0] * M.shape[1]):
        temp.append(M.T.item(i))
    V = np.asarray(temp)
    return V


def matrixize(V, C_dimension):
    temp = np.zeros(shape=(C_dimension, len(V) / C_dimension))
    for i in range(len(V) / C_dimension):
        temp.T[i] = V[i * C_dimension : (i + 1) * C_dimension]
    W = temp
    return W


&#47&#47 read centroids from file
def getClusters(fileNameWriteCluster):
    with open(fileNameWriteCluster, "r") as f:
        clusters = []
        for line in f:
            vec = []
            line = line.split(" ")
            for i in range(len(line) - 1):
                vec.append(float(line[i]))
            clusters.append(np.asarray(vec))
        return np.asarray(clusters)


def getArticleDic(fileNameRead):
    with open(fileNameRead, "r") as f:
        articleDict = {}
        l = 0
        for line in f:
            featureVec = []
            if l &gt;= 1:
                line = line.split(";")
                word = line[1].split("  ")

                if len(word) == 5:
                    for i in range(5):
                        featureVec.append(float(word[i]))
                    if int(line[0]) not in articleDict:
                        articleDict[int(line[0])] = np.asarray(featureVec)
            l += 1
    return articleDict


&#47&#47 get cluster assignment of V, M is cluster centroids
def getIDAssignment(V, M):
    MinDis = float("+inf")
    assignment = None
    for i in range(M.shape[0]):
        dis = distance.euclidean(V, M[i])
        if dis &lt; MinDis:
            assignment = i
            MinDis = dis
    return assignment


&#47&#47 This code simply reads one line from the source files of Yahoo!
def parseLine(line):
    line = line.split("|")

    tim, articleID, click = line[0].strip().split(" ")
    tim, articleID, click = int(tim), int(articleID), int(click)
    user_features = np.array(
        [float(x.strip().split(":")[1]) for x in line[1].strip().split(" ")[1:]]
    )

    pool_articles = [l.strip().split(" ") for l in line[2:]]
    pool_articles = np.array(
        [[int(l[0])] + [float(x.split(":")[1]) for x in l[1:]] for l in pool_articles]
    )
    return tim, articleID, click, user_features, pool_articles


&#47&#47 read line with userID instead of user features
def parseLine_ID(line):
    line = line.split("|")

    tim, articleID, click = line[0].strip().split(" ")
    tim, articleID, click = int(tim), int(articleID), int(click)

    userID = int(line[1].strip())

    pool_articles = [l.strip().split(" ") for l in line[2:]]
    pool_articles = np.array(
        [[int(l[0])] + [float(x.split(":")[1]) for x in l[1:]] for l in pool_articles]
    )
    return tim, articleID, click, userID, pool_articles


def save_to_file(fileNameWrite, recordedStats, tim):
    with open(fileNameWrite, "a+") as f:
        f.write("data")  &#47&#47 the observation line starts with data;
        f.write("," + str(tim))
        f.write("," + ";".join([str(x) for x in recordedStats]))
        f.write("\n")


def initializeGW(W, epsilon):
    n = len(W)
    G = np.zeros(shape=(n, n))
    for i in range(n):
        for j in range(n):
            if W[i][j] &gt; 0:
                G[i][j] = 1
    L = csgraph.laplacian(G, normed=False)
    I = np.identity(n)
    GW = I + epsilon * L
    print(GW)

    return GW


def initializeW(userFeatureVectors, sparsityLevel):
    n = len(userFeatureVectors)
    W = np.zeros(shape=(n, n))

    for i in range(n):
        sSim = 0
        for j in range(n):
            sim = np.dot(userFeatureVectors[i], userFeatureVectors[j])
            W[i][j] = sim
            sSim += sim

        W[i] /= sSim
    SparseW = W

    if sparsityLevel &gt; 0 and sparsityLevel &lt; n:
        print("Yesyesyes")
        for i in range(n):
            similarity = sorted(W[i], reverse=True)
            threshold = similarity[sparsityLevel]
            for j in range(n):
                if W[i][j] &lt;= threshold:
                    SparseW[i][j] = 0
            SparseW[i] /= sum(SparseW[i])

    print("SparseW", SparseW)
    return SparseW.T


def initializeW_opt(userFeatureVectors, sparsityLevel):
    n = len(userFeatureVectors)
    W = np.zeros(shape=(n, n))

    for i in range(n):
        sSim = 0
        for j in range(n):
            sim = np.dot(userFeatureVectors[i], userFeatureVectors[j])
            if i == j:
                W[i][j] = 0
            else:
                W[i][j] = sim
            sSim += sim
    SparseW = W

    if sparsityLevel &gt; 0 and sparsityLevel &lt; n:
        for i in range(n):
            similarity = sorted(W[i], reverse=True)
            threshold = similarity[sparsityLevel]
            for j in range(n):
                if W[i][j] &lt;= threshold:
                    SparseW[i][j] = 0

    for i in range(n):
        SparseW[i][i] = 0
        if sum(SparseW[i]) != 0:
            SparseW[i][i] = np.linalg.norm(SparseW[i]) ** 2 / sum(SparseW[i])
        else:
            SparseW[i][i] = 1
        SparseW[i] /= sum(SparseW[i])
    print("SparseW --Opt", SparseW)
    return SparseW.T


def showheatmap(W):
    plt.pcolor(W)
    plt.colorbar()
    plt.show()


def model_dump(obj, filename, line, day):
    <a id="change">fout</a><a id="change"> = open(filename + ".txt", "w")</a>
    fout.write("day\t" + str(day))
    fout.write("line\t" + str(linenum))
    <a id="change">fout</a><a id="change">.close()</a>
    <a id="change">fout</a><a id="change"> = open(filename + ".model", "w")</a>
    pickle.dump(obj, fout)
    <a id="change">fout</a><a id="change">.close()</a>


&#47&#47 data structure to store ctr
class articleAccess:
    def __init__(self):
        self.accesses = 0.0  &#47&#47 times the article was chosen to be presented as the best articles
        self.clicks = 0.0  &#47&#47 of times the article was actually clicked by the user
        self.CTR = 0.0  &#47&#47 ctr as calculated by the updateCTR function

    def updateCTR(self):
        try:
            self.CTR = self.clicks / self.accesses
        except ZeroDivisionError:  &#47&#47 if it has not been accessed
            self.CTR = -1
        return self.CTR

    def addrecord(self, click):
        self.clicks += click
        self.accesses += 1
</code></pre>