<link rel="stylesheet" href="../../../..//default.css">
<script src="../../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/awslabs/mxboard/blob/master/python/mxboard/summary.py#L208">GitHubLink</a>


<a href="https://github.com/maldil/mxboard/blob/master/python/mxboard/summary.py#L208">GitMyHubLink</a>

&#47&#47 Licensed to the Apache Software Foundation (ASF) under one
&#47&#47 or more contributor license agreements.  See the NOTICE file
&#47&#47 distributed with this work for additional information
&#47&#47 regarding copyright ownership.  The ASF licenses this file
&#47&#47 to you under the Apache License, Version 2.0 (the
&#47&#47 "License"); you may not use this file except in compliance
&#47&#47 with the License.  You may obtain a copy of the License at
&#47&#47
&#47&#47   http://www.apache.org/licenses/LICENSE-2.0
&#47&#47
&#47&#47 Unless required by applicable law or agreed to in writing,
&#47&#47 software distributed under the License is distributed on an
&#47&#47 "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
&#47&#47 KIND, either express or implied.  See the License for the
&#47&#47 specific language governing permissions and limitations
&#47&#47 under the License.

Functions of generating summary protocol buffers. Adapted from
https://github.com/lanpa/tensorboard-pytorch/blob/master/tensorboardX/summary.py

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import logging
import io
import wave
import struct
import json
import re as _re
import numpy as np

try:
    import mxnet
    from distutils.version import LooseVersion
    if LooseVersion(mxnet.__version__) &lt; LooseVersion(&quot1.2.0&quot):
        logging.warning(&quotThe currently installed MXNet version %s is less than 1.2.0.&quot
                        &quot Some functionality of MXBoard may not work.&quot, mxnet.__version__)
except ImportError:
    raise ImportError(&quotMXBoard requires MXNet with version &gt;= 1.2.0.&quot
                      &quot Please follow the instruction here to install MXNet first.&quot
                      &quot http://mxnet.incubator.apache.org/install/index.html&quot)

from mxnet.ndarray import NDArray
from mxnet.symbol import Symbol
from mxnet.gluon import HybridBlock
from .proto.summary_pb2 import Summary
from .proto.summary_pb2 import HistogramProto
from .proto.summary_pb2 import SummaryMetadata
from .proto.tensor_pb2 import TensorProto
from .proto.tensor_shape_pb2 import TensorShapeProto
from .proto.plugin_pr_curve_pb2 import PrCurvePluginData
from .proto.node_def_pb2 import NodeDef
from .proto.graph_pb2 import GraphDef
from .proto.attr_value_pb2 import AttrValue
from .proto.versions_pb2 import VersionDef
from .utils import _make_numpy_array, _prepare_image
try:
    from PIL import Image
except ImportError:
    Image = None


_INVALID_TAG_CHARACTERS = _re.compile(r&quot[^-/\w\.]&quot)


def _clean_tag(name):
    Cleans a tag. Removes illegal characters for instance.
    Adapted from the TensorFlow function `clean_tag()` at
    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/summary_op_util.py

    Parameters
    ----------
        name : str
            The original tag name to be processed.

    Returns
    -------
        The cleaned tag name.
    
    &#47&#47 In the past, the first argument to summary ops was a tag, which allowed
    &#47&#47 arbitrary characters. Now we are changing the first argument to be the node
    &#47&#47 name. This has a number of advantages (users of summary ops now can
    &#47&#47 take advantage of the tf name scope system) but risks breaking existing
    &#47&#47 usage, because a much smaller set of characters are allowed in node names.
    &#47&#47 This function replaces all illegal characters with _s, and logs a warning.
    &#47&#47 It also strips leading slashes from the name.
    if name is not None:
        new_name = _INVALID_TAG_CHARACTERS.sub(&quot_&quot, name)
        new_name = new_name.lstrip(&quot/&quot)  &#47&#47 Remove leading slashes
        if new_name != name:
            logging.warning(&quotSummary name %s is illegal; using %s instead.&quot, name, new_name)
            name = new_name
    return name


def scalar_summary(tag, scalar):
    Outputs a `Summary` protocol buffer containing a single scalar value.
    The generated Summary has a Tensor.proto containing the input Tensor.
    Adapted from the TensorFlow function `scalar()` at
    https://github.com/tensorflow/tensorflow/blob/r1.6/tensorflow/python/summary/summary.py

    Parameters
    ----------
      tag : str
          A name for the generated summary. Will also serve as the series name in TensorBoard.
      scalar : int, MXNet `NDArray`, or `numpy.ndarray`
          A scalar value or an ndarray of shape (1,).

    Returns
    -------
      A `Summary` protobuf of the `scalar` value.

    Raises
    ------
      ValueError: If the scalar has the wrong shape or type.
    
    tag = _clean_tag(tag)
    scalar = _make_numpy_array(scalar)
    assert(scalar.squeeze().ndim == 0), &quotscalar should be 0D&quot
    scalar = float(scalar)
    return Summary(value=[Summary.Value(tag=tag, simple_value=scalar)])


def histogram_summary(tag, values, bins):
    Outputs a `Summary` protocol buffer with a histogram.
    Adding a histogram summary makes it possible to visualize the data&quots distribution in
    TensorBoard. See detailed explanation of the TensorBoard histogram dashboard at
    https://www.tensorflow.org/get_started/tensorboard_histograms
    This op reports an `InvalidArgument` error if any value is not finite.
    Adapted from the TensorFlow function `histogram()` at
    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/summary/summary.py

    Parameters
    ----------
        tag : str
            A name for the summary of the histogram. Will also serve as a series name in
            TensorBoard.
        values : MXNet `NDArray` or `numpy.ndarray`
            Values for building the histogram.

    Returns
    -------
        A `Summary` protobuf of the histogram.
    
    tag = _clean_tag(tag)
    values = _make_numpy_array(values)
    hist = _make_histogram(values.astype(float), bins)
    return Summary(value=[Summary.Value(tag=tag, histo=hist)])


def _make_histogram(values, bins):
    Converts values into a histogram proto using logic from
    https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/histogram/histogram.cc
    values = values.reshape(-1)
    counts, limits = np.histogram(values, bins=bins)
    limits = limits[1:]

    sum_sq = values.dot(values)
    return HistogramProto(min=values.min(),
                          max=values.max(),
                          num=len(values),
                          sum=values.sum(),
                          sum_squares=sum_sq,
                          bucket_limit=limits,
                          bucket=counts)


def image_summary(tag, image):
    Outputs a `Summary` protocol buffer with image(s).

    Parameters
    ----------
        tag : str
            A name for the generated summary. Will also serve as a series name in TensorBoard.
        image : MXNet `NDArray` or `numpy.ndarray`
            Image data that is one of the following layout: (H, W), (C, H, W), (N, C, H, W).
            The pixel values of the image are assumed to be normalized in the range [0, 1].
            The image will be rescaled to the range [0, 255] and cast to `np.uint8` before creating
            the image protobuf.

    Returns
    -------
        A `Summary` protobuf of the image.
    
    tag = _clean_tag(tag)
    image = _prepare_image(image)
    image = _make_image(image)
    return Summary(value=[Summary.Value(tag=tag, image=image)])


def _make_image(tensor):
    Converts an NDArray type image to Image protobuf
    assert isinstance(tensor, NDArray)
    if Image is None:
        raise ImportError(&quotneed to install PIL for visualizing images&quot)
    height, width, channel = tensor.shape
    tensor = _make_numpy_array(tensor)
    image = Image.fromarray(tensor)
    output = io.BytesIO()
    image.save(output, format=&quotPNG&quot)
    image_string = output.getvalue()
    output.close()
    return Summary.Image(height=height, width=width, colorspace=channel,
                         encoded_image_string=image_string)


def audio_summary(tag, audio, sample_rate=44100):
    Outputs a `Summary` protocol buffer with audio data.

    Parameters
    ----------
        tag : str
            A name for the generated summary. Will also serve as a series name in TensorBoard.
        audio : MXNet `NDArray` or `numpy.ndarray`
            Audio data that can be squeezed into 1D array. The values are in the range [-1, 1].
        sample_rate : int
            Sampling frequency. 44,100Hz is a common sampling frequency.

    Returns
    -------
        A `Summary` protobuf of the audio data.
    
    audio = audio.squeeze()
    if audio.ndim != 1:
        raise ValueError(&quotinput audio must be squeezable to 1D, input audio squeezed &quot
                         &quotshape is {}&quot.format(audio.shape))
    audio = _make_numpy_array(audio)
    tensor_list = [int(32767.0 * x) for x in audio]
    <a id="change">fio</a> = io.BytesIO()
    <a id="change">wave_writer</a><a id="change"> = wave.open(fio, &quotwb&quot)</a>
    <a id="change">wave_writer</a>.setnchannels(1)
    <a id="change">wave_writer</a>.setsampwidth(2)
    <a id="change">wave_writer</a>.setframerate(sample_rate)
    tensor_enc = b&quot&quot
    for v in tensor_list:  &#47&#47 pylint: disable=invalid-name
        tensor_enc += struct.pack(&quot&lt;h&quot, v)
    <a id="change">wave_writer</a>.writeframes(tensor_enc)
    <a id="change">wave_writer</a><a id="change">.close()</a>
    audio_string = <a id="change">fio</a>.getvalue()
    <a id="change">fio</a><a id="change">.close()</a>
    audio = Summary.Audio(sample_rate=sample_rate,
                          num_channels=1,
                          length_frames=len(tensor_list),
                          encoded_audio_string=audio_string,
                          content_type=&quotaudio/wav&quot)
    return Summary(value=[Summary.Value(tag=tag, audio=audio)])


def text_summary(tag, text):
    Outputs a `Summary` protocol buffer with audio data.

    Parameters
    ----------
        tag : str
            A name for the generated summary. Will also serve as a series name in TensorBoard.
        text : str
            Text data.

    Returns
    -------
        A `Summary` protobuf of the audio data.
    
    plugin_data = [SummaryMetadata.PluginData(plugin_name=&quottext&quot)]
    smd = SummaryMetadata(plugin_data=plugin_data)
    tensor = TensorProto(dtype=&quotDT_STRING&quot,
                         string_val=[text.encode(encoding=&quotutf_8&quot)],
                         tensor_shape=TensorShapeProto(dim=[TensorShapeProto.Dim(size=1)]))
    return Summary(value=[Summary.Value(node_name=tag, metadata=smd, tensor=tensor)])


def pr_curve_summary(tag, labels, predictions, num_thresholds, weights=None):
    Outputs a precision-recall curve `Summary` protocol buffer.

    Parameters
    ----------
        tag : str
            A tag attached to the summary. Used by TensorBoard for organization.
        labels : MXNet `NDArray` or `numpy.ndarray`.
            The ground truth values. A tensor of 0/1 values with arbitrary shape.
        predictions : MXNet `NDArray` or `numpy.ndarray`.
            A float32 tensor whose values are in the range `[0, 1]`. Dimensions must
            match those of `labels`.
        num_thresholds : int
            Number of thresholds, evenly distributed in `[0, 1]`, to compute PR metrics for.
            Should be `&gt;= 2`. This value should be a constant integer value, not a tensor
            that stores an integer.
            The thresholds for computing the pr curves are calculated in the following way:
            `width = 1.0 / (num_thresholds - 1),
            thresholds = [0.0, 1*width, 2*width, 3*width, ..., 1.0]`.
        weights : MXNet `NDArray` or `numpy.ndarray`.
            Optional float32 tensor. Individual counts are multiplied by this value.
            This tensor must be either the same shape as or broadcastable to the `labels` tensor.

    Returns
    -------
        A `Summary` protobuf of the pr_curve.
    
    &#47&#47 num_thresholds &gt; 127 results in failure of creating protobuf,
    &#47&#47 probably a bug of protobuf
    if num_thresholds &gt; 127:
        logging.warning(&quotnum_thresholds&gt;127 would result in failure of creating pr_curve protobuf,&quot
                        &quot clipping it at 127&quot)
        num_thresholds = 127
    labels = _make_numpy_array(labels)
    predictions = _make_numpy_array(predictions)
    if weights is not None:
        weights = _make_numpy_array(weights)
    data = _compute_curve(labels, predictions, num_thresholds=num_thresholds, weights=weights)
    pr_curve_plugin_data = PrCurvePluginData(version=0,
                                             num_thresholds=num_thresholds).SerializeToString()
    plugin_data = [SummaryMetadata.PluginData(plugin_name=&quotpr_curves&quot,
                                              content=pr_curve_plugin_data)]
    smd = SummaryMetadata(plugin_data=plugin_data)
    tensor = TensorProto(dtype=&quotDT_FLOAT&quot,
                         float_val=data.reshape(-1).tolist(),
                         tensor_shape=TensorShapeProto(
                             dim=[TensorShapeProto.Dim(size=data.shape[0]),
                                  TensorShapeProto.Dim(size=data.shape[1])]))
    return Summary(value=[Summary.Value(tag=tag, metadata=smd, tensor=tensor)])


&#47&#47 A value that we use as the minimum value during division of counts to prevent
&#47&#47 division by 0. 1.0 does not work: Certain weights could cause counts below 1.
_MINIMUM_COUNT = 1e-7


def _compute_curve(labels, predictions, num_thresholds, weights=None):
    This function is another implementation of functions in
    https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/summary.py

    if weights is None:
        weights = 1.0

    &#47&#47 Compute bins of true positives and false positives.
    bucket_indices = np.int32(np.floor(predictions * (num_thresholds - 1)))
    float_labels = labels.astype(np.float)
    histogram_range = (0, num_thresholds - 1)
    tp_buckets, _ = np.histogram(
        bucket_indices,
        bins=num_thresholds,
        range=histogram_range,
        weights=float_labels * weights)
    fp_buckets, _ = np.histogram(
        bucket_indices,
        bins=num_thresholds,
        range=histogram_range,
        weights=(1.0 - float_labels) * weights)

    &#47&#47 Obtain the reverse cumulative sum.
    tp = np.cumsum(tp_buckets[::-1])[::-1]
    fp = np.cumsum(fp_buckets[::-1])[::-1]
    tn = fp[0] - fp
    fn = tp[0] - tp
    precision = tp / np.maximum(_MINIMUM_COUNT, tp + fp)
    recall = tp / np.maximum(_MINIMUM_COUNT, tp + fn)
    return np.stack((tp, fp, tn, fn, precision, recall))


def _scoped_name(scope_name, node_name):
    return &quot/&quot.join([scope_name, node_name])


def _get_nodes_from_symbol(sym):
    Given a symbol and shapes, return a list of `NodeDef`s for visualizing the
    the graph in TensorBoard.
    if not isinstance(sym, Symbol):
        raise TypeError(&quotsym must be an `mxnet.symbol.Symbol`,&quot
                        &quot received type {}&quot.format(str(type(sym))))
    conf = json.loads(sym.tojson())
    nodes = conf[&quotnodes&quot]
    data2op = {}  &#47&#47 key: data id, value: list of ops to whom data is an input
    for i, node in enumerate(nodes):
        if node[&quotop&quot] != &quotnull&quot:  &#47&#47 node is an operator
            input_list = node[&quotinputs&quot]
            for idx in input_list:
                if idx[0] == 0:  &#47&#47 do not include &quotdata&quot node in the op scope
                    continue
                if idx[0] in data2op:
                    &#47&#47 nodes[idx[0]] is a data as an input to op nodes[i]
                    data2op[idx[0]].append(i)
                else:
                    data2op[idx[0]] = [i]

    &#47&#47 In the following, we group data with operators they belong to
    &#47&#47 by attaching them with operator names as scope names.
    &#47&#47 The parameters with the operator name as the prefix will be
    &#47&#47 assigned with the scope name of that operator. For example,
    &#47&#47 a convolution op has name &quotconv&quot, while its weight and bias
    &#47&#47 have name &quotconv_weight&quot and &quotconv_bias&quot. In the end, the operator
    &#47&#47 has scope name &quotconv&quot prepended to its name, i.e. &quotconv/conv&quot.
    &#47&#47 The parameters are named &quotconv/conv_weight&quot and &quotconv/conv_bias&quot.
    node_defs = []
    for i, node in enumerate(nodes):
        node_name = node[&quotname&quot]
        op_name = node[&quotop&quot]
        kwargs = {&quotop&quot: op_name, &quotname&quot: node_name}
        if op_name != &quotnull&quot:  &#47&#47 node is an operator
            inputs = []
            input_list = node[&quotinputs&quot]
            for idx in input_list:
                input_node = nodes[idx[0]]
                input_node_name = input_node[&quotname&quot]
                if input_node[&quotop&quot] != &quotnull&quot:
                    inputs.append(_scoped_name(input_node_name, input_node_name))
                elif idx[0] in data2op and len(data2op[idx[0]]) == 1 and data2op[idx[0]][0] == i:
                    &#47&#47 the data is only as an input to nodes[i], no else
                    inputs.append(_scoped_name(node_name, input_node_name))
                else:  &#47&#47 the data node has no scope name, e.g. &quotdata&quot as the input node
                    inputs.append(input_node_name)
            kwargs[&quotinput&quot] = inputs
            kwargs[&quotname&quot] = _scoped_name(node_name, node_name)
        elif i in data2op and len(data2op[i]) == 1:
            &#47&#47 node is a data node belonging to one op, find out which operator this node belongs to
            op_node_name = nodes[data2op[i][0]][&quotname&quot]
            kwargs[&quotname&quot] = _scoped_name(op_node_name, node_name)

        if &quotattrs&quot in node:
            &#47&#47 TensorBoard would escape quotation marks, replace it with space
            attr = json.dumps(node[&quotattrs&quot], sort_keys=True).replace("\"", &quot &quot)
            attr = {&quotparam&quot: AttrValue(s=attr.encode(encoding=&quotutf-8&quot))}
            kwargs[&quotattr&quot] = attr
        node_def = NodeDef(**kwargs)
        node_defs.append(node_def)
    return node_defs


def _sym2pb(sym):
    Converts an MXNet symbol to its graph protobuf definition.
    return GraphDef(node=_get_nodes_from_symbol(sym), versions=VersionDef(producer=100))


def _net2pb(net):
    if isinstance(net, HybridBlock):
        &#47&#47 TODO(junwu): may need a more approprite way to get symbol from a HybridBlock
        if not net._cached_graph:
            raise RuntimeError(
                "Please first call net.hybridize() and then run forward with "
                "this net at least once before calling add_graph().")
        net = net._cached_graph[1]
    elif not isinstance(net, Symbol):
        raise TypeError(&quotonly accepts mxnet.gluon.HybridBlock and mxnet.symbol.Symbol &quot
                        &quotas input network, received type {}&quot.format(str(type(net))))
    return _sym2pb(net)
</code></pre>