<link rel="stylesheet" href="../../../..//default.css">
<script src="../../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/jwyang/faster-rcnn.pytorch/blob/master/lib/datasets/imagenet.py#L89">GitHubLink</a>


<a href="https://github.com/maldil/faster-rcnn.pytorch/blob/master/lib/datasets/imagenet.py#L89">GitMyHubLink</a>

from __future__ import print_function
&#47&#47 --------------------------------------------------------
&#47&#47 Fast R-CNN
&#47&#47 Copyright (c) 2015 Microsoft
&#47&#47 Licensed under The MIT License [see LICENSE for details]
&#47&#47 Written by Ross Girshick
&#47&#47 --------------------------------------------------------

import datasets
import datasets.imagenet
import os, sys
from datasets.imdb import imdb
import xml.dom.minidom as minidom
import numpy as np
import scipy.sparse
import scipy.io as sio
import subprocess
import pdb
import pickle
try:
    xrange          &#47&#47 Python 2
except NameError:
    xrange = range  &#47&#47 Python 3


class imagenet(imdb):
    def __init__(self, image_set, devkit_path, data_path):
        imdb.__init__(self, image_set)
        self._image_set = image_set
        self._devkit_path = devkit_path
        self._data_path = data_path
        synsets_image = sio.loadmat(os.path.join(self._devkit_path, &quotdata&quot, &quotmeta_det.mat&quot))
        synsets_video = sio.loadmat(os.path.join(self._devkit_path, &quotdata&quot, &quotmeta_vid.mat&quot))
        self._classes_image = (&quot__background__&quot,)
        self._wnid_image = (0,)

        self._classes = (&quot__background__&quot,)
        self._wnid = (0,)

        for i in xrange(200):
            self._classes_image = self._classes_image + (synsets_image[&quotsynsets&quot][0][i][2][0],)
            self._wnid_image = self._wnid_image + (synsets_image[&quotsynsets&quot][0][i][1][0],)

        for i in xrange(30):
            self._classes = self._classes + (synsets_video[&quotsynsets&quot][0][i][2][0],)
            self._wnid = self._wnid + (synsets_video[&quotsynsets&quot][0][i][1][0],)

        self._wnid_to_ind_image = dict(zip(self._wnid_image, xrange(201)))
        self._class_to_ind_image = dict(zip(self._classes_image, xrange(201)))

        self._wnid_to_ind = dict(zip(self._wnid, xrange(31)))
        self._class_to_ind = dict(zip(self._classes, xrange(31)))

        &#47&#47check for valid intersection between video and image classes
        self._valid_image_flag = [0]*201

        for i in range(1,201):
            if self._wnid_image[i] in self._wnid_to_ind:
                self._valid_image_flag[i] = 1

        self._image_ext = [&quot.JPEG&quot]

        self._image_index = self._load_image_set_index()
        &#47&#47 Default to roidb handler
        self._roidb_handler = self.gt_roidb

        &#47&#47 Specific config options
        self.config = {&quotcleanup&quot  : True,
                       &quotuse_salt&quot : True,
                       &quottop_k&quot    : 2000}

        assert os.path.exists(self._devkit_path), &quotDevkit path does not exist: {}&quot.format(self._devkit_path)
        assert os.path.exists(self._data_path), &quotPath does not exist: {}&quot.format(self._data_path)

    def image_path_at(self, i):
        
        Return the absolute path to image i in the image sequence.
        
        return self.image_path_from_index(self._image_index[i])

    def image_path_from_index(self, index):
        
        Construct an image path from the image&quots "index" identifier.
        
        image_path = os.path.join(self._data_path, &quotData&quot, self._image_set, index + self._image_ext[0])
        assert os.path.exists(image_path), &quotpath does not exist: {}&quot.format(image_path)
        return image_path

    def _load_image_set_index(self):
        
        Load the indexes listed in this dataset&quots image set file.
        
        &#47&#47 Example path to image set file:
        &#47&#47 self._data_path + /ImageSets/val.txt

        if self._image_set == &quottrain&quot:
            image_set_file = os.path.join(self._data_path, &quotImageSets&quot, &quottrainr.txt&quot)
            image_index = []
            if os.path.exists(image_set_file):
                <a id="change">f</a><a id="change"> = open(image_set_file, &quotr&quot)</a>
                data = <a id="change">f</a>.read().split()
                for lines in data:
                    if lines != &quot&quot:
                        <a id="change">image_index</a>.append(lines)
                <a id="change">f</a><a id="change">.close()</a>
                return image_index

            for i in range(1,200):
                print(i)
                image_set_file = os.path.join(self._data_path, &quotImageSets&quot, &quotDET&quot, &quottrain_&quot + str(i) + &quot.txt&quot)
                with open(image_set_file) as f:
                    tmp_index = [<a id="change">x</a>.strip() for x in <a id="change">f</a>.readlines()]
                    vtmp_index = []
                    for line in tmp_index:
                        line = <a id="change">line</a>.split(&quot &quot)
                        image_list = os.popen(&quotls &quot + self._data_path + &quot/Data/DET/train/&quot + line[0] + &quot/*.JPEG&quot).read().split()
                        tmp_list = []
                        for imgs in image_list:
                            <a id="change">tmp_list</a>.append(imgs[:-5])
                        vtmp_index = vtmp_index + tmp_list

                num_lines = len(vtmp_index)
                ids = np.random.permutation(num_lines)
                count = 0
                while count &lt; 2000:
                    <a id="change">image_index</a>.append(vtmp_index[ids[count % num_lines]])
                    count = count + 1

            for i in range(1,201):
                if self._valid_image_flag[i] == 1:
                    image_set_file = os.path.join(self._data_path, &quotImageSets&quot, &quottrain_pos_&quot + str(i) + &quot.txt&quot)
                    with open(image_set_file) as f:
                        tmp_index = [<a id="change">x</a>.strip() for x in <a id="change">f</a>.readlines()]
                    num_lines = len(tmp_index)
                    ids = np.random.permutation(num_lines)
                    count = 0
                    while count &lt; 2000:
                        <a id="change">image_index</a>.append(tmp_index[ids[count % num_lines]])
                        count = count + 1
            image_set_file = os.path.join(self._data_path, &quotImageSets&quot, &quottrainr.txt&quot)
            <a id="change">f</a><a id="change"> = open(image_set_file, &quotw&quot)</a>
            for lines in image_index:
                <a id="change">f</a>.write(lines + &quot\n&quot)
            <a id="change">f</a><a id="change">.close()</a>
        else:
            image_set_file = os.path.join(self._data_path, &quotImageSets&quot, &quotval.txt&quot)
            with open(image_set_file) as f:
                image_index = [<a id="change">x</a>.strip() for x in <a id="change">f</a>.readlines()]
        return image_index

    def gt_roidb(self):
        
        Return the database of ground-truth regions of interest.
        This function loads/saves from/to a cache file to speed up future calls.
        
        cache_file = os.path.join(self.cache_path, self.name + &quot_gt_roidb.pkl&quot)
        if os.path.exists(cache_file):
            with open(cache_file, &quotrb&quot) as fid:
                roidb = pickle.load(fid)
            print(&quot{} gt roidb loaded from {}&quot.format(self.name, cache_file))
            return roidb

        gt_roidb = [self._load_imagenet_annotation(index)
                    for index in self.image_index]
        with open(cache_file, &quotwb&quot) as fid:
            pickle.dump(gt_roidb, fid, pickle.HIGHEST_PROTOCOL)
        print(&quotwrote gt roidb to {}&quot.format(cache_file))

        return gt_roidb


    def _load_imagenet_annotation(self, index):
        
        Load image and bounding boxes info from txt files of imagenet.
        
        filename = os.path.join(self._data_path, &quotAnnotations&quot, self._image_set, index + &quot.xml&quot)

        &#47&#47 print &quotLoading: {}&quot.format(filename)
        def get_data_from_tag(node, tag):
            return node.getElementsByTagName(tag)[0].childNodes[0].data

        with open(filename) as f:
            data = minidom.parseString(f.read())

        objs = data.getElementsByTagName(&quotobject&quot)
        num_objs = len(objs)

        boxes = np.zeros((num_objs, 4), dtype=np.uint16)
        gt_classes = np.zeros((num_objs), dtype=np.int32)
        overlaps = np.zeros((num_objs, self.num_classes), dtype=np.float32)

        &#47&#47 Load object bounding boxes into a data frame.
        for ix, obj in enumerate(objs):
            x1 = float(get_data_from_tag(obj, &quotxmin&quot))
            y1 = float(get_data_from_tag(obj, &quotymin&quot))
            x2 = float(get_data_from_tag(obj, &quotxmax&quot))
            y2 = float(get_data_from_tag(obj, &quotymax&quot))
            cls = self._wnid_to_ind[
                    str(get_data_from_tag(obj, "name")).lower().strip()]
            boxes[ix, :] = [x1, y1, x2, y2]
            gt_classes[ix] = cls
            overlaps[ix, cls] = 1.0

        overlaps = scipy.sparse.csr_matrix(overlaps)

        return {&quotboxes&quot : boxes,
                &quotgt_classes&quot: gt_classes,
                &quotgt_overlaps&quot : overlaps,
                &quotflipped&quot : False}

if __name__ == &quot__main__&quot:
    d = datasets.imagenet(&quotval&quot, &quot&quot)
    res = d.roidb
    from IPython import embed; embed()
</code></pre>