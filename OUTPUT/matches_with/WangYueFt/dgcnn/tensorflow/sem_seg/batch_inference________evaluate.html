<link rel="stylesheet" href="../../../..//default.css">
<script src="../../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/WangYueFt/dgcnn/blob/master/tensorflow/sem_seg/batch_inference.py#L39">GitHubLink</a>


<a href="https://github.com/maldil/dgcnn/blob/master/tensorflow/sem_seg/batch_inference.py#L39">GitMyHubLink</a>

import argparse
import os
import sys
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(BASE_DIR)
sys.path.append(BASE_DIR)
from model import *
import indoor3d_util

parser = argparse.ArgumentParser()
parser.add_argument(&quot--gpu&quot, type=int, default=0, help=&quotGPU to use [default: GPU 0]&quot)
parser.add_argument(&quot--batch_size&quot, type=int, default=1, help=&quotBatch Size during training [default: 1]&quot)
parser.add_argument(&quot--num_point&quot, type=int, default=4096, help=&quotPoint number [default: 4096]&quot)
parser.add_argument(&quot--model_path&quot, required=True, help=&quotmodel checkpoint file path&quot)
parser.add_argument(&quot--dump_dir&quot, required=True, help=&quotdump folder path&quot)
parser.add_argument(&quot--output_filelist&quot, required=True, help=&quotTXT filename, filelist, each line is an output for a room&quot)
parser.add_argument(&quot--room_data_filelist&quot, required=True, help=&quotTXT filename, filelist, each line is a test room data label file.&quot)
parser.add_argument(&quot--no_clutter&quot, action=&quotstore_true&quot, help=&quotIf true, donot count the clutter class&quot)
parser.add_argument(&quot--visu&quot, action=&quotstore_true&quot, help=&quotWhether to output OBJ file for prediction visualization.&quot)
FLAGS = parser.parse_args()

BATCH_SIZE = FLAGS.batch_size
NUM_POINT = FLAGS.num_point
MODEL_PATH = FLAGS.model_path
GPU_INDEX = FLAGS.gpu
DUMP_DIR = FLAGS.dump_dir
if not os.path.exists(DUMP_DIR): os.mkdir(DUMP_DIR)
LOG_FOUT = open(os.path.join(DUMP_DIR, &quotlog_evaluate.txt&quot), &quotw&quot)
LOG_FOUT.write(str(FLAGS)+&quot\n&quot)
ROOM_PATH_LIST = [os.path.join(ROOT_DIR,line.rstrip()) for line in open(FLAGS.room_data_filelist)]

NUM_CLASSES = 13

def log_string(out_str):
  LOG_FOUT.write(out_str+&quot\n&quot)
  LOG_FOUT.flush()
  print(out_str)

def evaluate():
  is_training = False
   
  with tf.device(&quot/gpu:&quot+str(GPU_INDEX)):
    pointclouds_pl, labels_pl = placeholder_inputs(BATCH_SIZE, NUM_POINT)
    is_training_pl = tf.placeholder(tf.bool, shape=())

    pred = get_model(pointclouds_pl, is_training_pl)
    loss = get_loss(pred, labels_pl)
    pred_softmax = tf.nn.softmax(pred)
 
    saver = tf.train.Saver()
    
  config = tf.ConfigProto()
  config.gpu_options.allow_growth = True
  config.allow_soft_placement = True
  sess = tf.Session(config=config)

  saver.restore(sess, MODEL_PATH)
  log_string("Model restored.")

  ops = {&quotpointclouds_pl&quot: pointclouds_pl,
       &quotlabels_pl&quot: labels_pl,
       &quotis_training_pl&quot: is_training_pl,
       &quotpred&quot: pred,
       &quotpred_softmax&quot: pred_softmax,
       &quotloss&quot: loss}
  
  total_correct = 0
  total_seen = 0
  <a id="change">fout_out_filelist = open(FLAGS.output_filelist, &quotw&quot)</a>
  for room_path in ROOM_PATH_LIST:
    out_data_label_filename = os.path.basename(room_path)[:-4] + &quot_pred.txt&quot
    out_data_label_filename = os.path.join(DUMP_DIR, out_data_label_filename)
    out_gt_label_filename = os.path.basename(room_path)[:-4] + &quot_gt.txt&quot
    out_gt_label_filename = os.path.join(DUMP_DIR, out_gt_label_filename)
   
    print(room_path, out_data_label_filename)
    &#47&#47 Evaluate room one by one.
    a, b = eval_one_epoch(sess, ops, room_path, out_data_label_filename, out_gt_label_filename)
    total_correct += a
    total_seen += b
    fout_out_filelist.write(out_data_label_filename+&quot\n&quot)
  <a id="change">fout_out_filelist</a><a id="change">.close()</a>
  log_string(&quotall room eval accuracy: %f&quot% (total_correct / float(total_seen)))

def eval_one_epoch(sess, ops, room_path, out_data_label_filename, out_gt_label_filename):
  error_cnt = 0
  is_training = False
  total_correct = 0
  total_seen = 0
  loss_sum = 0
  total_seen_class = [0 for _ in range(NUM_CLASSES)]
  total_correct_class = [0 for _ in range(NUM_CLASSES)]

  if FLAGS.visu:
    fout = open(os.path.join(DUMP_DIR, os.path.basename(room_path)[:-4]+&quot_pred.obj&quot), &quotw&quot)
    fout_gt = open(os.path.join(DUMP_DIR, os.path.basename(room_path)[:-4]+&quot_gt.obj&quot), &quotw&quot)
    fout_real_color = open(os.path.join(DUMP_DIR, os.path.basename(room_path)[:-4]+&quot_real_color.obj&quot), &quotw&quot)
  fout_data_label = open(out_data_label_filename, &quotw&quot)
  fout_gt_label = open(out_gt_label_filename, &quotw&quot)
  
  current_data, current_label = indoor3d_util.room2blocks_wrapper_normalized(room_path, NUM_POINT)
  current_data = current_data[:,0:NUM_POINT,:]
  current_label = np.squeeze(current_label)
  &#47&#47 Get room dimension..
  data_label = np.load(room_path)
  data = data_label[:,0:6]
  max_room_x = max(data[:,0])
  max_room_y = max(data[:,1])
  max_room_z = max(data[:,2])
  
  file_size = current_data.shape[0]
  num_batches = file_size // BATCH_SIZE
  print(file_size)

  
  for batch_idx in range(num_batches):
    start_idx = batch_idx * BATCH_SIZE
    end_idx = (batch_idx+1) * BATCH_SIZE
    cur_batch_size = end_idx - start_idx
    
    feed_dict = {ops[&quotpointclouds_pl&quot]: current_data[start_idx:end_idx, :, :],
           ops[&quotlabels_pl&quot]: current_label[start_idx:end_idx],
           ops[&quotis_training_pl&quot]: is_training}
    loss_val, pred_val = sess.run([ops[&quotloss&quot], ops[&quotpred_softmax&quot]],
                    feed_dict=feed_dict)

    if FLAGS.no_clutter:
      pred_label = np.argmax(pred_val[:,:,0:12], 2) &#47&#47 BxN
    else:
      pred_label = np.argmax(pred_val, 2) &#47&#47 BxN
    
    &#47&#47 Save prediction labels to OBJ file
    for b in range(BATCH_SIZE):
      pts = current_data[start_idx+b, :, :]
      l = current_label[start_idx+b,:]
      pts[:,6] *= max_room_x
      pts[:,7] *= max_room_y
      pts[:,8] *= max_room_z
      pts[:,3:6] *= 255.0
      pred = pred_label[b, :]
      for i in range(NUM_POINT):
        color = indoor3d_util.g_label2color[pred[i]]
        color_gt = indoor3d_util.g_label2color[current_label[start_idx+b, i]]
        if FLAGS.visu:
          fout.write(&quotv %f %f %f %d %d %d\n&quot % (pts[i,6], pts[i,7], pts[i,8], color[0], color[1], color[2]))
          fout_gt.write(&quotv %f %f %f %d %d %d\n&quot % (pts[i,6], pts[i,7], pts[i,8], color_gt[0], color_gt[1], color_gt[2]))
        fout_data_label.write(&quot%f %f %f %d %d %d %f %d\n&quot % (pts[i,6], pts[i,7], pts[i,8], pts[i,3], pts[i,4], pts[i,5], pred_val[b,i,pred[i]], pred[i]))
        fout_gt_label.write(&quot%d\n&quot % (l[i]))
    
    correct = np.sum(pred_label == current_label[start_idx:end_idx,:])
    total_correct += correct
    total_seen += (cur_batch_size*NUM_POINT)
    loss_sum += (loss_val*BATCH_SIZE)
    for i in range(start_idx, end_idx):
      for j in range(NUM_POINT):
        l = current_label[i, j]
        total_seen_class[l] += 1
        total_correct_class[l] += (pred_label[i-start_idx, j] == l)

  log_string(&quoteval mean loss: %f&quot % (loss_sum / float(total_seen/NUM_POINT)))
  log_string(&quoteval accuracy: %f&quot% (total_correct / float(total_seen)))
  fout_data_label.close()
  fout_gt_label.close()
  if FLAGS.visu:
    fout.close()
    fout_gt.close()
  return total_correct, total_seen


if __name__==&quot__main__&quot:
  with tf.Graph().as_default():
    evaluate()
  LOG_FOUT.close()
</code></pre>