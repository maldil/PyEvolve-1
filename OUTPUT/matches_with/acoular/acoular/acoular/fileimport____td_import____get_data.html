<link rel="stylesheet" href="../../..//default.css">
<script src="../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/acoular/acoular/blob/master/acoular/fileimport.py#L120">GitHubLink</a>


<a href="https://github.com/maldil/acoular/blob/master/acoular/fileimport.py#L120">GitMyHubLink</a>

&#47&#47 -*- coding: utf-8 -*-
&#47&#47pylint: disable-msg=E0611, E1101, C0103, R0901, R0902, R0903, R0904, W0232
&#47&#47------------------------------------------------------------------------------
&#47&#47 Copyright (c) Acoular Development Team.
&#47&#47------------------------------------------------------------------------------

Contains classes for importing time data in several file formats.
Standard HDF (`*.h5`) import can be done using 
:class:`~acoular.sources.TimeSamples` objects.

.. autosummary::
    :toctree: generated/

    time_data_import
    csv_import
    td_import
    bk_mat_import
    datx_import


from numpy import fromstring, float32, newaxis, empty, sort, zeros
from traits.api import HasPrivateTraits, Float, Int, \
File, CArray, Property, Any, Str
from os import path
import pickle
import configparser
import struct

&#47&#47 acoular imports
from .h5files import H5CacheFileBase, _get_h5file_class
from .configuration import config
class time_data_import( HasPrivateTraits ):
    
    Base class for import of time data.
    

    def get_data (self, td):
        
        Imports the data into an arbitrary time_data object td.
        This is a dummy function and should not be used directly.
        
        td.data = None
        td.numsamples = 0
        td.numchannels = 0
        td.sample_freq = 0

class csv_import( time_data_import ):
    
    Class that supports the import of CSV data as saved by NI VI Logger.
    

    &#47&#47: Name of the comma delimited file to import.
    from_file = File(filter = [&quot*.txt&quot], 
        desc = "name of the comma delimited file to import")

    &#47&#47: Header length, defaults to 6.
    header_length =  Int(6, 
        desc = "length of the header to ignore during import")

    &#47&#47: Number of leading columns (will be ignored during import), defaults to 1.
    dummy_columns = Int(1, 
        desc = "number of leading columns to ignore during import")

    def get_data (self, td):
        
        Imports the data from CSV file into a
        :class:`~acoular.sources.TimeSamples` object `td`.
        Also, a `*.h5` file will be written, so this import
        need not be performed every time the data is needed
        
        if not path.isfile(self.from_file):
            &#47&#47 no file there
            time_data_import.get_data(self, td)
            return
        &#47&#47import data
        c = self.header_length
        d = self.dummy_columns
        f = open(self.from_file)
        &#47&#47read header
        for line in f:
            c -= 1
            h = line.split(&quot:&quot)
            if h[0] == &quotScan rate&quot:
                sample_freq = int(1./float(h[1].split(&quot &quot)[1]))
            if c == 0:
                break
        line = next(f)
        data = fromstring(line, dtype = float32, sep = &quot, &quot)[d:]
        numchannels = len(data)
        name = td.name
        if name == "":
            name = path.join(config.td_dir, \
                path.splitext(path.basename(self.from_file))[0]+&quot.h5&quot)
        else:
            if td.h5f !=  None:
                td.h5f.close()
        &#47&#47 TODO problems with already open h5 files from other instances
        file = _get_h5file_class()
        f5h = file(name, mode = &quotw&quot)
        f5h.create_extendable_array(
                &quottime_data&quot, (0, numchannels), "float32")
        ac = f5h.get_data_by_reference(&quottime_data&quot)
        f5h.set_node_attribute(ac,&quotsample_freq&quot,sample_freq)
        f5h.append_data(ac,data[newaxis, :])
        for line in f:
            f5h.append_data(ac,fromstring(line, dtype=float32, sep=&quot, &quot)[newaxis, d:])
        f5h.close()
        td.name = name
        td.load_data()

class td_import( time_data_import ):
    
    Import of `*.td` data as saved by earlier versions
    

    &#47&#47: Name of the comma delimited file to import.
    from_file = File(filter = [&quot*.td&quot], 
        desc = "name of the *.td file to import")

    def get_data (<a id="change">self</a>, <a id="change">td</a>):
        
        Main work is done here: imports the data from `*.td` file into
        TimeSamples object `td` and saves also a `*.h5` file so this import
        need not be performed only once.
        
        if not path.isfile(self.from_file):
            &#47&#47 no file there
            time_data_import.get_data(self, td)
            return
        <a id="change">f = open(self.from_file, &quotrb&quot)</a>
        <a id="change">h = pickle.load(f)</a>
        <a id="change">f</a><a id="change">.close()</a>
        <a id="change">sample_freq = h[&quotsample_freq&quot]</a>
        <a id="change">data = h[&quotdata&quot]</a>
        <a id="change">numchannels = data.shape[1]</a>
        <a id="change">name = td.name</a>
        if name == "":
            <a id="change">name = path.join(config.td_dir, \
                        path.splitext(path.basename(self.from_file))[0]+&quot.h5&quot)</a>
        else:
            if td.h5f !=  None:
                td.h5f.close()
        &#47&#47 TODO problems with already open h5 files from other instances
        <a id="change">file = _get_h5file_class()</a>
        <a id="change">f5h = file(name, mode = &quotw&quot)</a>
        f5h.create_extendable_array(
                &quottime_data&quot, (0, numchannels), "float32")
        <a id="change">ac = f5h.get_data_by_reference(&quottime_data&quot)</a>
        f5h.set_node_attribute(ac,&quotsample_freq&quot,sample_freq)
        f5h.append_data(ac,data)
        f5h.close()
        <a id="change">td.name = name</a>
        td.load_data()


class bk_mat_import( time_data_import ):
    
    Import of BK pulse matlab data.
    

    &#47&#47: Name of the mat file to import
    from_file = File(filter = [&quot*.mat&quot], 
        desc = "name of the BK pulse mat file to import")

    def get_data (self, td):
        
        Main work is done here: imports the data from pulse .mat file into
        time_data object &quottd&quot and saves also a `*.h5` file so this import
        need not be performed every time the data is needed.
        
        if not path.isfile(self.from_file):
            &#47&#47 no file there
            time_data_import.get_data(self, td)
            return
        &#47&#47import data
        from scipy.io import loadmat
        m = loadmat(self.from_file)
        fh = m[&quotFile_Header&quot]
        numchannels = int(fh.NumberOfChannels)
        l = int(fh.NumberOfSamplesPerChannel)
        sample_freq = float(fh.SampleFrequency.replace(&quot, &quot, &quot.&quot))
        data = empty((l, numchannels), &quotf&quot)
        for i in range(numchannels):
            &#47&#47 map SignalName "Point xx" to channel xx-1
            ii = int(m["Channel_%i_Header" % (i+1)].SignalName[-2:])-1
            data[:, ii] = m["Channel_%i_Data" % (i+1)]
        name = td.name
        if name == "":
            name = path.join(config.td_dir, \
                path.splitext(path.basename(self.from_file))[0]+&quot.h5&quot)
        else:
            if td.h5f !=  None:
                td.h5f.close()
        &#47&#47 TODO problems with already open h5 files from other instances
        file = _get_h5file_class()
        f5h = file(name, mode = &quotw&quot)
        f5h.create_extendable_array(
                &quottime_data&quot, (0, numchannels), "float32")
        ac = f5h.get_data_by_reference(&quottime_data&quot)
        f5h.set_node_attribute(ac,&quotsample_freq&quot,sample_freq)
        f5h.append_data(ac,data)
        f5h.close()
        td.name = name
        td.load_data()

class datx_d_file(HasPrivateTraits):
    
    Helper class for import of `*.datx` data, represents
    datx data file.
    
    &#47&#47 File name
    name = File(filter = [&quot*.datx&quot], 
        desc = "name of datx data file")

    &#47&#47 File object
    f = Any()

    &#47&#47 Properties
    data_offset = Int()
    channel_count = Int()
    num_samples_per_block = Int()
    bytes_per_sample = Int()
    block_size = Property()

    &#47&#47 Number of blocks to read in one pull
    blocks = Int()
    &#47&#47 The actual block data
    data = CArray()

    def _get_block_size( self ):
        return self.channel_count*self.num_samples_per_block*\
                self.bytes_per_sample

    def get_next_blocks( self ):
         pulls next blocks 
        s = self.f.read(self.blocks*self.block_size)
        ls = len(s)
        if ls == 0:
            return -1
        bl_no = ls/self.block_size
        self.data = fromstring(s, dtype = &quotInt16&quot).reshape((bl_no, \
            self.channel_count, self.num_samples_per_block)).swapaxes(0, \
            1).reshape((self.channel_count, bl_no*self.num_samples_per_block))

    def __init__(self, name, blocks = 128):
        self.name = name
        self.f = open(self.name, &quotrb&quot)
        s = self.f.read(32)
        &#47&#47 header
        s0 = struct.unpack(&quotIIIIIIHHf&quot, s)        
        &#47&#47 Getting information about Properties of data-file 
        &#47&#47 3 = Offset to data 4 = channel count 
        &#47&#47 5 = number of samples per block 6 = bytes per sample
        self.data_offset = s0[3]
        self.channel_count = s0[4]
        self.num_samples_per_block = s0[5]
        self.bytes_per_sample = s0[6]
        self.blocks = blocks
        self.f.seek(self.data_offset)

class datx_channel(HasPrivateTraits):
    
    Helper class for import of .datx data, represents
    one channel.
    

    label = Str()
    d_file = Str()
    ch_no = Int()
    ch_K = Str()
    volts_per_count = Float()
    msl_ccf = Float()
    cal_corr_factor = Float()
    internal_gain = Float()
    external_gain = Float()
    tare_volts = Float()
    cal_coeff_2 = Float()
    cal_coeff_1 = Float()
    tare_eu = Float()
    z0 = Float()


    def __init__(self, config, channel):
        d_file, ch_no, ch_K = config.get(&quotchannels&quot, channel).split(&quot, &quot) 
        &#47&#47 Extraction and Splitting of Channel information
        self.d_file = d_file
        self.ch_no = int(ch_no)
        self.label = config.get(ch_K, &quotchannel_label&quot)
        self.ch_K = ch_K
        &#47&#47 V                                                     
        &#47&#47 Reading conversion factors
        self.volts_per_count = float(config.get(ch_K, &quotvolts_per_count&quot))
        self.msl_ccf = float(config.get(ch_K, &quotmsl_ccf&quot))
        self.cal_corr_factor = float(config.get(ch_K, &quotcal_corr_factor&quot))
        self.internal_gain = float(config.get(ch_K, &quotinternal_gain&quot))
        self.external_gain = float(config.get(ch_K, &quotexternal_gain&quot))
        self.tare_volts = float(config.get(ch_K, &quottare_volts&quot))
        &#47&#47 EU
        self.cal_coeff_2 = float(config.get(ch_K, &quotcal_coeff_2&quot))
        self.cal_coeff_1 = float(config.get(ch_K, &quotcal_coeff_1&quot))
        self.tare_eu = float(config.get(ch_K, &quottare_eu&quot))
        self.z0 = (self.volts_per_count * self.msl_ccf * self.cal_corr_factor) \
                    / (self.internal_gain * self.external_gain)

    def scale(self, x):
         scale function to produce output in engineering units 
        return (x * self.z0 - self.tare_volts) * self.cal_coeff_2 + \
                self.cal_coeff_1 - self.tare_eu

class datx_import(time_data_import):
    
    Import of .datx data
    

    &#47&#47: Name of the datx index file to import.
    from_file = File(filter = [&quot*.datx_index&quot], 
        desc = "name of the datx index file to import")

    def get_data (self, td):
        
        Main work is done here: imports the data from datx files into
        time_data object td and saves also a `*.h5` file so this import
        need not be performed every time the data is needed
        
        if not path.isfile(self.from_file):
            &#47&#47 no file there
            time_data_import.get_data(self, td)
            return
        &#47&#47browse datx information
        f0 = open(self.from_file)
        config = configparser.ConfigParser()
        config.readfp(f0)
        sample_rate = float(config.get(&quotkeywords&quot, &quotsample_rate&quot))
        &#47&#47 reading sample-rate from index-file
        channels = []
        d_files = {}
        &#47&#47 Loop over all channels assigned in index-file
        for channel in sort(config.options(&quotchannels&quot)):
            ch = datx_channel(config, channel)
            if ch.label.find(&quotMic&quot) &gt;= 0:
                channels.append(ch)
                if not d_files.has_key(ch.d_file):
                    d_files[ch.d_file] = \
                        datx_d_file(path.join(path.dirname(self.from_file), \
                            config.get(ch.d_file, &quotfn&quot)), 32)
        numchannels = len(channels)
        &#47&#47 prepare hdf5
        name = td.name
        if name == "":
            name = path.join(config.td_dir, \
                path.splitext(path.basename(self.from_file))[0]+&quot.h5&quot)
        else:
            if td.h5f !=  None:
                td.h5f.close()
        &#47&#47 TODO problems with already open h5 files from other instances
        file = _get_h5file_class()
        f5h = file(name, mode = &quotw&quot)
        f5h.create_extendable_array(
                &quottime_data&quot, (0, numchannels), "float32")
        ac = f5h.get_data_by_reference(&quottime_data&quot)
        f5h.set_node_attribute(ac,&quotsample_freq&quot,sample_rate)
        block_data = \
            zeros((128*d_files[channels[0].d_file].num_samples_per_block, \
                numchannels), &quotFloat32&quot)
        flag = 0
        while(not flag):
            for i in d_files.values():
                flag = i.get_next_blocks()
            if flag:
                continue
            for i in range(numchannels):
                data = d_files[channels[i].d_file].data[channels[i].ch_no]
                block_data[:data.size, i] = channels[i].scale(data)
            f5h.append_data(ac,block_data[:data.size])
        f5h.close()
        f0.close()
        for i in d_files.values():
            i.f.close()
        td.name = name
        td.load_data()
</code></pre>