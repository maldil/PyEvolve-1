<link rel="stylesheet" href="../../../../../../..//default.css">
<script src="../../../../../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/Microsoft/nni/blob/master/examples/model_compress/pruning/legacy/mobilenetv2_end2end/pretrain.py#L39">GitHubLink</a>


<a href="https://github.com/maldil/nni/blob/master/examples/model_compress/pruning/legacy/mobilenetv2_end2end/pretrain.py#L39">GitMyHubLink</a>

&#47&#47 Copyright (c) Microsoft Corporation.
&#47&#47 Licensed under the MIT license.

import os
import argparse
from time import gmtime, strftime
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np

from utils import *


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def run_validation(model, valid_dataloader):
    model.eval()
    
    loss_func = nn.CrossEntropyLoss()
    acc_list, loss_list = [], []
    with torch.no_grad():
        for i, (inputs, labels) in enumerate(tqdm(valid_dataloader)):
            inputs, labels = inputs.float().to(device), labels.to(device)
            preds= model(inputs)
            pred_idx = preds.max(1).indices
            acc = (pred_idx == labels).sum().item() / labels.size(0)
            acc_list.append(acc)
            loss = loss_func(preds, labels).item()
            loss_list.append(loss)

    valid_loss = np.array(loss_list).mean()
    valid_acc = np.array(acc_list).mean()
    
    return valid_loss, valid_acc


def run_pretrain(args):
    print(args)
    torch.set_num_threads(args.n_workers)
    
    <a id="change">model_type</a> = &quotmobilenet_v2_torchhub&quot   
    pretrained = True                      &#47&#47 load imagenet weight
    <a id="change">experiment_dir</a> = &quotpretrained_{}&quot.format(model_type) if args.experiment_dir is None else args.experiment_dir
    os.mkdir(experiment_dir)
    checkpoint = None
    input_size = 224
    n_classes = 120
    
    <a id="change">log</a><a id="change"> = open(experiment_dir + &quot/pretrain.log&quot, &quotw&quot)</a>
    
    <a id="change">model</a> = create_model(model_type=model_type, pretrained=pretrained, n_classes=n_classes,
                         input_size=input_size, checkpoint=checkpoint)
    <a id="change">model</a> = model.to(device)
    print(model)
    &#47&#47 count_flops(model, device=device)

    <a id="change">train_dataset</a> = TrainDataset(&quot./data/stanford-dogs/Processed/train&quot)
    <a id="change">train_dataloader</a> = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)
    <a id="change">valid_dataset</a> = EvalDataset(&quot./data/stanford-dogs/Processed/valid&quot)
    <a id="change">valid_dataloader</a> = DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False)

    criterion = nn.CrossEntropyLoss()
    <a id="change">optimizer</a> = torch.optim.SGD(model.parameters(), lr=args.learning_rate, momentum=0.9, weight_decay=args.weight_decay)

    <a id="change">best_valid_acc</a> = 0.0
    for <a id="change">epoch</a> in range(args.n_epochs):
        print(&quotStart training epoch {}&quot.format(epoch))
        <a id="change">loss_list</a> = []

        &#47&#47 train
        model.train()
        for <a id="change">i</a>, (inputs, labels) in enumerate(tqdm(train_dataloader)):
            optimizer.zero_grad()
            inputs, labels = inputs.float().to(device), labels.to(device)
            <a id="change">preds</a> = model(inputs)
            <a id="change">loss</a> = criterion(preds, labels)
            loss_list.append(loss.item())
            loss.backward()
            optimizer.step()
            
        &#47&#47 validation
        valid_loss, valid_acc = run_validation(model, valid_dataloader)
        <a id="change">train_loss</a> = np.array(loss_list).mean()
        print(&quotEpoch {}: train loss {:.4f}, valid loss {:.4f}, valid acc {:.4f}&quot.format
              (epoch, train_loss, valid_loss, valid_acc))
        log.write(&quotEpoch {}: train loss {:.4f}, valid loss {:.4f}, valid acc {:.4f}\n&quot.format
                  (epoch, train_loss, valid_loss, valid_acc))
        
        &#47&#47 save
        if valid_acc &gt; best_valid_acc:
            best_valid_acc = valid_acc
            torch.save(model.state_dict(), experiment_dir + &quot/checkpoint_best.pt&quot)

    <a id="change">log</a><a id="change">.close()</a>


def parse_args():
    parser = argparse.ArgumentParser(description=&quotExample code for pruning MobileNetV2&quot)

    parser.add_argument(&quot--experiment_dir&quot, type=str, default=None,
                        help=&quotdirectory containing the pretrained model&quot)
    parser.add_argument(&quot--checkpoint_name&quot, type=str, default=&quotcheckpoint_best.pt&quot,
                         help=&quotcheckpoint of the pretrained model&quot)
    
    &#47&#47 finetuning parameters
    parser.add_argument(&quot--n_workers&quot, type=int, default=16,
                        help=&quotnumber of threads&quot)
    parser.add_argument(&quot--n_epochs&quot, type=int, default=180,
                        help=&quotnumber of epochs to train the model&quot)
    parser.add_argument(&quot--learning_rate&quot, type=float, default=1e-4)
    parser.add_argument(&quot--weight_decay&quot, type=float, default=0.0)
    parser.add_argument(&quot--batch_size&quot, type=int, default=32,
                        help=&quotinput batch size for training and inference&quot)

    args = parser.parse_args()
    return args

    
if __name__ == &quot__main__&quot:
    args = parse_args()
    run_pretrain(args)
</code></pre>