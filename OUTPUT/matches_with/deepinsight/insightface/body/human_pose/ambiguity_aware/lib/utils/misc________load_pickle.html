<link rel="stylesheet" href="../../../../../../..//default.css">
<script src="../../../../../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/deepinsight/insightface/blob/master/body/human_pose/ambiguity_aware/lib/utils/misc.py#L56">GitHubLink</a>


<a href="https://github.com/maldil/insightface/blob/master/body/human_pose/ambiguity_aware/lib/utils/misc.py#L56">GitMyHubLink</a>

import os 
import os.path as osp
import h5py
import math
import time
import logging 
import pickle as pkl 
import torch.nn as nn
from pathlib import Path

def create_logger(cfg, cfg_name):
    root_output_dir = Path(cfg.OUTPUT_DIR)
    if not root_output_dir.exists():
        print(f&quot=&gt; creating {root_output_dir}&quot)
    cfg_name = osp.basename(cfg_name).split(&quot.&quot)[0]
    final_output_dir = root_output_dir / cfg_name
    print(f&quot=&gt; creating {final_output_dir}&quot)
    final_output_dir.mkdir(parents=True, exist_ok=True)
    
    time_str = time.strftime(&quot%Y-%m-%d-%H-%M&quot)
    log_file = &quot{}_{}.log&quot.format(cfg_name, time_str)
    final_log_file = final_output_dir / log_file 
    head = &quot%(asctime)-15s %(message)s&quot
    logging.basicConfig(filename=str(final_log_file), format=head)
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    console = logging.StreamHandler()
    logging.getLogger(&quot&quot).addHandler(console)

    tensorboard_log_dir = Path(cfg.LOG_DIR) / (cfg_name + "_" + time_str)
    print(f"=&gt; creating {tensorboard_log_dir}")
    tensorboard_log_dir.mkdir(parents=True, exist_ok=True)
    return logger, str(final_output_dir), str(tensorboard_log_dir)

def init_weights(model):
    for m in model.modules(): 
        if isinstance(m, nn.Conv2d):
            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
            m.weight.data.normal_(0, math.sqrt(2. / n))
        elif isinstance(m, nn.BatchNorm2d):
            m.weight.data.fill_(1)
            m.bias.data.zero_()
        elif isinstance(m, nn.BatchNorm1d):
            m.weight.data.fill_(1)
            m.bias.data.zero_()
        elif isinstance(m, nn.Linear):
            m.weight.data.normal_(0, 0.02)
            m.bias.data.zero_()
    
def save_pickle(data, save_path):
    f = open(save_path, "wb")
    pkl.dump(data, f)
    f.close()
    print(f"=&gt; saved to {save_path}")

def load_pickle(load_path):
    <a id="change">f = open(load_path, "rb")</a>
    data = pkl.load(f)
    <a id="change">f</a><a id="change">.close()</a>
    print(f"&lt;= loaded from {load_path}")
    return data 

def process_dataset_for_video(path, is_mpi=False):
    &#47&#47 add some content for specified dataset(h5)
    f = h5py.File(path, "a")
    imagenames = [name.decode() for name in f[&quotimagename&quot][:]]
    seqnames = [&quot/&quot.join(name.split(&quot/&quot)[:-1]) for name in imagenames]
    if is_mpi: 
        indices_in_seq_ref = [int(name.split(&quot/&quot)[-1].split(&quot.&quot)[0].split(&quot_&quot)[1]) for name in imagenames]
        &#47&#47 reset indices 
        indices_in_seq = []
        i = 0 
        last_seqname = None
        for index, seqname in zip(indices_in_seq_ref, seqnames): 
            if last_seqname is not None and seqname != last_seqname: 
                i = 0 
            last_seqname = seqname 
            indices_in_seq.append(i)
            i += 1
        &#47&#47 indices_in_seq = [i for i, index in enumerate(indices_in_seq)]
    else: 
        indices_in_seq = [int(name.split(&quot/&quot)[-1]) for name in imagenames]
    f[&quotindex_in_seq&quot] = indices_in_seq
    f[&quotseqname&quot] = [name.encode() for name in seqnames]
    seq_lens = {}
    for seqname in seqnames: 
        if seqname not in seq_lens: 
            seq_lens[seqname] = 0 
        seq_lens[seqname] += 1

    f[&quotseqlen&quot] = [seq_lens[seqname] for seqname in seqnames]
    f.close()

</code></pre>