<link rel="stylesheet" href="../../..//default.css">
<script src="../../..//highlight.pack.js"></script> 
<script>hljs.initHighlightingOnLoad();</script>
<html><pre><code class='java'>
<a href="https://github.com/nl8590687/ASRT_SpeechRecognition/blob/master/utils/ops.py#L141">GitHubLink</a>


<a href="https://github.com/maldil/ASRT_SpeechRecognition/blob/master/utils/ops.py#L141">GitMyHubLink</a>

&#47&#47!/usr/bin/env python3
&#47&#47 -*- coding: utf-8 -*-
&#47&#47
&#47&#47 Copyright 2016-2099 Ailemon.net
&#47&#47
&#47&#47 This file is part of ASRT Speech Recognition Tool.
&#47&#47
&#47&#47 ASRT is free software: you can redistribute it and/or modify
&#47&#47 it under the terms of the GNU General Public License as published by
&#47&#47 the Free Software Foundation, either version 3 of the License, or
&#47&#47 (at your option) any later version.
&#47&#47 ASRT is distributed in the hope that it will be useful,
&#47&#47 but WITHOUT ANY WARRANTY; without even the implied warranty of
&#47&#47 MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
&#47&#47 GNU General Public License for more details.
&#47&#47
&#47&#47 You should have received a copy of the GNU General Public License
&#47&#47 along with ASRT.  If not, see &lt;https://www.gnu.org/licenses/&gt;.
&#47&#47 ============================================================================


@author: nl8590687
一些常用操作函数的定义


import wave
import difflib
import matplotlib.pyplot as plt
import numpy as np

def read_wav_data(filename: str) -&gt; tuple:
    &quot&quot&quot
    读取一个wav文件，返回声音信号的时域谱矩阵和播放时间
    &quot&quot&quot
    wav = wave.open(filename,"rb") &#47&#47 打开一个wav格式的声音文件流
    num_frame = wav.getnframes() &#47&#47 获取帧数
    num_channel=wav.getnchannels() &#47&#47 获取声道数
    framerate=wav.getframerate() &#47&#47 获取帧速率
    num_sample_width=wav.getsampwidth() &#47&#47 获取实例的比特宽度，即每一帧的字节数
    str_data = wav.readframes(num_frame) &#47&#47 读取全部的帧
    wav.close() &#47&#47 关闭流
    wave_data = np.fromstring(str_data, dtype = np.short) &#47&#47 将声音文件数据转换为数组矩阵形式
    wave_data.shape = -1, num_channel &#47&#47 按照声道数将数组整形，单声道时候是一列数组，双声道时候是两列的矩阵
    wave_data = wave_data.T &#47&#47 将矩阵转置
    return wave_data, framerate, num_channel, num_sample_width

def read_wav_bytes(filename: str) -&gt; tuple:
    &quot&quot&quot
    读取一个wav文件，返回声音信号的时域谱矩阵和播放时间
    &quot&quot&quot
    wav = wave.open(filename,"rb") &#47&#47 打开一个wav格式的声音文件流
    num_frame = wav.getnframes() &#47&#47 获取帧数
    num_channel=wav.getnchannels() &#47&#47 获取声道数
    framerate=wav.getframerate() &#47&#47 获取帧速率
    num_sample_width=wav.getsampwidth() &#47&#47 获取实例的比特宽度，即每一帧的字节数
    str_data = wav.readframes(num_frame) &#47&#47 读取全部的帧
    wav.close() &#47&#47 关闭流
    return str_data, framerate, num_channel, num_sample_width

def get_edit_distance(str1, str2) -&gt; int:
    &quot&quot&quot
    计算两个串的编辑距离，支持str和list类型
    &quot&quot&quot
    leven_cost = 0
    sequence_match = difflib.SequenceMatcher(None, str1, str2)
    for tag, index_1, index_2, index_j1, index_j2 in sequence_match.get_opcodes():
        if tag == &quotreplace&quot:
            leven_cost += max(index_2-index_1, index_j2-index_j1)
        elif tag == &quotinsert&quot:
            leven_cost += (index_j2-index_j1)
        elif tag == &quotdelete&quot:
            leven_cost += (index_2-index_1)
    return leven_cost

def ctc_decode_delete_tail_blank(ctc_decode_list):
    &quot&quot&quot
    处理CTC解码后序列末尾余留的空白元素，删除掉
    &quot&quot&quot
    p = 0
    while p &lt; len(ctc_decode_list) and ctc_decode_list[p] != -1:
        p += 1
    return ctc_decode_list[0:p]

def visual_1D(points_list, frequency=1):
    &quot&quot&quot
    可视化1D数据
    &quot&quot&quot
    &#47&#47 首先创建绘图网格，1个子图
    fig, ax = plt.subplots(1)
    x = np.linspace(0, len(points_list)-1, len(points_list)) / frequency

    &#47&#47 在对应对象上调用 plot() 方法
    ax.plot(x, points_list)
    fig.show()

def visual_2D(img):
    &quot&quot&quot
    可视化2D数据
    &quot&quot&quot
    plt.subplot(111)
    plt.imshow(img)
    plt.colorbar(cax=None, ax=None, shrink=0.5)
    plt.show() 

def decode_wav_bytes(samples_data: bytes, channels: int = 1, byte_width: int = 2) -&gt; list:
    &quot&quot&quot
    解码wav格式样本点字节流，得到numpy数组
    &quot&quot&quot
    numpy_type = np.short
    if byte_width == 4:
        numpy_type = np.int
    elif byte_width != 2:
        raise Exception(&quoterror: unsurpport byte width `&quot + str(byte_width) + &quot`&quot)
    wave_data = np.fromstring(samples_data, dtype = numpy_type) &#47&#47 将声音文件数据转换为数组矩阵形式
    wave_data.shape = -1, channels &#47&#47 按照声道数将数组整形，单声道时候是一列数组，双声道时候是两列的矩阵
    wave_data = wave_data.T &#47&#47 将矩阵转置
    return wave_data

def get_symbol_dict(dict_filename):
    &quot&quot&quot
    读取拼音汉字的字典文件
    返回读取后的字典
    &quot&quot&quot
    txt_obj = open(dict_filename, &quotr&quot, encoding=&quotUTF-8&quot) &#47&#47 打开文件并读入
    txt_text = txt_obj.read()
    txt_obj.close()
    txt_lines = txt_text.split(&quot\n&quot) &#47&#47 文本分割

    dic_symbol = {} &#47&#47 初始化符号字典
    for i in txt_lines:
        list_symbol=[] &#47&#47 初始化符号列表
        if i!=&quot&quot:
            txt_l=i.split(&quot\t&quot)
            pinyin = txt_l[0]
            for word in txt_l[1]:
                list_symbol.append(word)
        dic_symbol[pinyin] = list_symbol

    return dic_symbol

def get_language_model(model_language_filename):
    &quot&quot&quot
    读取语言模型的文件
    返回读取后的模型
    &quot&quot&quot
    <a id="change">txt_obj</a><a id="change"> = open(model_language_filename, &quotr&quot, encoding=&quotUTF-8&quot)</a> &#47&#47 打开文件并读入
    <a id="change">txt_text</a> = txt_obj.read()
    <a id="change">txt_obj</a><a id="change">.close()</a>
    <a id="change">txt_lines</a> = txt_text.split(&quot\n&quot) &#47&#47 文本分割

    <a id="change">dic_model</a> = {} &#47&#47 初始化符号字典
    for <a id="change">i</a> in txt_lines:
        if i!=&quot&quot:
            <a id="change">txt_l</a>=i.split(&quot\t&quot)
            if len(txt_l) == 1:
                continue
            dic_model[txt_l[0]] = txt_l[1]

    return dic_model
</code></pre>